---
title: "| Spring 2020  \n| GE 461 Introduction to Data Science \n"
author: "| Hatim Zahid - 21603260"
always_allow_html: yes
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '4'
  bookdown::pdf_document2:
    number_sections: yes
    toc_depth: 4
  bookdown::html_document2:
    code_folding: hide
    number_sections: yes
    theme: readable
    toc: yes
    toc_float: no
link-citations: yes
linkcolor: red
bibliography: GE461.bib
pagetitle: GE 461 Introduction to Data Science
papersize: a4paper
<!-- title: <center> <h2> Spring 2020 </h2>  GE 461 Introduction to Data Science </center>
  -->
---

```{r setup, include=FALSE}
library(caret)
library(magrittr)
library(tidyverse)
library(knitr)
library(kableExtra)
library(pander)
opts_chunk$set(echo = TRUE)
options(knitr.kable.NA =".") 
kable_format <- if (is_html_output()) "html" else "latex"
options(scipen = 999)
```

# Introduction

The Dodgers is a professional baseball team and plays in the Major Baseball League. The team owns a 56,000-seat stadium and is interested in increasing the attendance of their fans during home games.*At the moment the team management would like to know if bobblehead promotions increase the attendance of the team's fans?* This is a case study based on @miller2014modeling[Chapter 2].

```{r, out.width=c("33%","33%","13%"), fig.align='center', fig.show="hold", fig.cap="56,000-seat Dodgers (left), stadium  (middle), shirts and caps  (right) *bobblehead*"}
include_graphics(c("los_angeles-dodgers-stadium.jpg",
                 "Los-Angeles-Dodgers-Promo.jpg",
                 "adrian_bobble.jpg"))
```

# Visualizing the whole dataset Table.
```{r }
library(RSQLite)
library(dplyr)
library(dbplyr)
library(pander)
library(knitr)
con <- dbConnect(SQLite(), "/sqlite/dodgers.sqlite")
## this will let sqlite do all jobs for us
events <-  tbl(con, "events")
d <- dbReadTable(con, "events")
events
```

# Q1 . Tabular and Box Plot analysis with Fireworks
# Is there an association between attendance and if there were fireworks or not ? 

```{r Fireworks variation across day}

d2 <- d %>%
mutate(day_of_week = factor(day_of_week, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")),
month = factor(month, levels = c("APR", "MAY", "JUN", "JUL", "AUG", "SEP", "OCT")))
d2 %>%
select(day_of_week, month) %>%
summary() %>%
pander(caption = "Month and week day names now follow time order.")
d2 %>%
count(day_of_week, fireworks, name = "cnt") %>%
pivot_wider(names_from = fireworks, values_from = cnt) %>%
rename(`Weekday` = day_of_week) %>%
kable(format = "html", caption = "Number of times Firework took place in games played different weekdays", booktabs=TRUE) %>%
kable_styling(full_width = FALSE) %>%
add_header_above(c(" "=1, "Firework"=2))

```

Fireworks were done only 14 times in 81 games. All were done on friday with only 1 done on wednesday.
13 games were played on friday which is same number of games played every day of the week. This is important as now number of games is same we can focus on the attendance variation between the days.
Did attendance vary between friday and other days? How advantageuos were the fireworks ?

# Q1. Box and scatter plots analysis between attendance and fireworks, cap, shirt , bobblehead
```{r Attendance Variation across days}

d2 %>%
ggplot(aes(fireworks, attend)) +
geom_boxplot(aes(fill=fireworks)) +
theme(legend.position = "none")

d2 %>%
ggplot(aes(cap, attend)) +
geom_boxplot(aes(fill=cap)) +
theme(legend.position = "none")

d2 %>%
ggplot(aes(shirt, attend)) +
geom_boxplot(aes(fill=shirt)) +
theme(legend.position = "none")

d2 %>%
ggplot(aes(bobblehead, attend)) +
geom_boxplot(aes(fill=bobblehead)) +
theme(legend.position = "none")





```


Fridays attendance average is same as any other day. Hence there is no relation seen between the fireworks and the attendance thru visualization !
Cap promotion also doesnt effect th attendance as the medians are the same when no caps were given.
Shirt promotion seems to increase attendance. There seems a positive relation between the shirt promotion and attendance. Attendance median increases by 10,000.


# Q1. Box plot and scatter plot of relation between attendance and Opponents.
#     Is there a relation between attendance and any particular opponent?
```{r Opponent :no of games and variation of attendance }

dk <- d %>%
mutate( opponent = factor( opponent, levels = c("Pirates", "Braves", "Nationals", "Giants", "Rockies", "Snakes", "Cardinals","Astros","Brewers", "Angels" , "White Sox", "Mets" , "Reds", "Padres", "Phillies" , "Cubs" , "Marlins")))

 dk %>% count( opponent , name = "Number_of_games") %>%
rename(`Opponent`= opponent) %>% 
pander(caption = "Number of games with each opponent");

d2 %>%
ggplot(aes(opponent, attend, group=1)) +
geom_point() +
scale_y_continuous(labels=scales::comma) +
geom_smooth(se=FALSE, method="loess")

d2 %>%
ggplot(aes(opponent, attend)) +
geom_boxplot(aes(fill=opponent)) +
theme(legend.position = "none")
```
There are different number og games played against each opponent hence a median value will better give us an understanding to compare the attendances. Angels have the highest average attendance while Brave have the lowest average attendance. Maximum attendance was however recorded in a Giants Game and a lowest attendance was recorded in a Sankes games. We can say that Angels bought in more crowd on average as if we compare it with other opponents against whom 3 games were played, angels bought in much higher crowds.



# Q1. Chi quare test between fireworks , opponents, shirt, cap.
#    we try to see if the relation is due to chance or not.

```{r Chi square tests}

fireworks_tbl <- d2 %>%
mutate(attend_cut = cut(attend, breaks = c(0, quantile(attend, prob=(1:2)/3), Inf))) %>%
xtabs(~ attend_cut + fireworks, .)
fireworks_tbl %>%
as_tibble() %>% pivot_wider(names_from= fireworks, values_from = n) %>%
kable(caption = "", booktabs = TRUE) %>%
kable_styling(full_width = FALSE) %>%
add_header_above(c(" "= 1, "Fireworks" = 2))
chisq.test(fireworks_tbl) %>% pander()

opponents_tbl <- d2 %>%
mutate(attend_cut = cut(attend, breaks = c(0, quantile(attend, prob=(1:2)/3), Inf))) %>%
xtabs(~ attend_cut + opponent, .)
opponents_tbl %>%
as_tibble() %>% pivot_wider(names_from= opponent, values_from = n) %>%
kable(caption = " ", booktabs = TRUE) %>%
kable_styling(full_width = FALSE) %>%
add_header_above(c(" "= 1, "Opponents" = 17))
chisq.test(opponents_tbl) %>% pander()


shirt_tbl <- d2 %>%
mutate(attend_cut = cut(attend, breaks = c(0, quantile(attend, prob=(1:2)/3), Inf))) %>%
xtabs(~ attend_cut + shirt, .)
shirt_tbl %>%
as_tibble() %>% pivot_wider(names_from= shirt, values_from = n) %>%
kable(caption = " ", booktabs = TRUE) %>%
kable_styling(full_width = FALSE) %>%
add_header_above(c(" "= 1, "Shirt" = 2))
chisq.test(shirt_tbl) %>% pander()

cap_tbl <- d2 %>%
mutate(attend_cut = cut(attend, breaks = c(0, quantile(attend, prob=(1:2)/3), Inf))) %>%
xtabs(~ attend_cut + cap, .)
cap_tbl %>%
as_tibble() %>% pivot_wider(names_from= cap, values_from = n) %>%
kable(caption = " ", booktabs = TRUE) %>%
kable_styling(full_width = FALSE) %>%
add_header_above(c(" "= 1, "Cap" = 2))
chisq.test(cap_tbl) %>% pander()

```
Null Hypothesis: Attendance and the other explanatory variable are independant.


Attendance and Firework : Chi square P value is 11.5%. It tells that fireworks and attendance may be independant, but we need to perform more accurate analysis with other tests, as no firm assurance is given by Chi test.

Attendance and Opponent: Chi square value is 4% which is less then 5%, it means that both variables are dependant. It rejects the null hypothesis.

Attendance and Cap: Null hypothesis accepted as p value is greater then 5%.

Attendance and shirt: Null hypothesis accepted as p value is greater then 5%.

</center>


# Q1. Linear Regression Analysis of all variables.

# a.  How good does your model ﬁt to data?

```{r}
lmod <- lm(attend ~. , d2)
lmod
summary(lmod)
```
1. The P-value of the F static is 2.4*10^(-4). It is closer to zero hence it means that some predictor variables are significantly related to the outcome variables.


# Q1. Checking the Beta Coefficients of all variables.

```{r}
summary(lmod)$coefficient
```

2. If a bobblehead is given the attendance increases by + 9349.
3. The t-values of fireworks and Bobblehead are the highest which means that we can believe in the beta cofficients with more confidence.
4. We should trust the beta coefficients of bobblehead and day_of_weekTuesday because they have the least pr>(|t|) value, which means coefficients are significant.
5. It seems from the analysis that Bobbleheadyes, day_of_weekTuesday and fireworks are important predictors of attendance. It is however contradictory that first in initial data visualizaion fireworks seemed insignificant.

This doesnt seem to be a good model because when we look at the adjusted R square value of the model it says that only 48% of the variance in the attendance can be predicted by the given explanatory variables.


# Q1. Linear Regression Model versus the Mean Model.
#    --Checking the Null Hypothesis

Now, we are comparing the linear regression model and the intercept only model : which is also called the mean model. This comparision is used to test the null hypothesis for regression analysis.

```{r}
small <- update(lmod, . ~ 1 )
anova(small, lmod)

```

Null hypothesis : The linear regression model and the mean model of the variable are the same.
if these models are same then the variable doesnt affect attendance.


P-value is small <= 0.05. We conclude that at least
one of variables on the right has some relation to attendance and reject null hypothesis.

# Q1. F-Tests for Statistical Significance. 

Now we check that if bobblehead,day_of_weekTuesday and fireworks are statiscally affecting the attendance.


```{r}
small <- update(lmod, . ~ . - bobblehead)
anova(small, lmod)

drop1(lmod, test="F")

```

The above results show that:
1. Bobblehead is most significant with the least p value and gives almost 100% confidence. Null hyp rejected.
2. Day of week is next most important as it gives 99% confidence . Null hyp rejected.
3. Fireworks is third most important as it gives 99% confidence. Null hyp rejected.
4. All other variables have high p vales. Null hyp accepted.


AIC analysis:
1. day_of_week is most significant as it will reduce future overestimation
2. bobbehead is second most important 
3. Fireworks is the third most important.


All explanatory variables are not required because they are not significant for predicting attendance.

# AIC Tests

```{r}
opt_drop1 <- lmod %>% step(direction='backward')
```





AIC analysis:
1. day_of_week is most significant as it will reduce future overestimation
2. bobbehead is second most important 
3. Fireworks is the third most important.


# Cross Validation tests : For bobblehead
This tests are done by taking each variable out from the model and then comparing the prediction results with the all variables model

```{r}
set.seed(500)
nfolds <- 5
folds <- rep(seq(5), nrow(d2), len=nrow(d2)) %>% sample()
rmse_lmod <- rep(NA, nfolds)
rmse_lmod_interaction <- rep(NA, nfolds)

lmodnew <-  update(lmod, . ~ . )
lmod_interaction <- update(lmod, . ~ . - bobblehead)

for (i in seq(nfolds)){
train <- d2[folds!=i,]
test <- d2[folds==i,]

# train lm without interaction model
lmod_train <- update(lmodnew, data = train)
lmod_test <- predict(lmod_train, newdata = test)
rmse_lmod[i] <- (test$attend - lmod_test)^2 %>% mean() %>% sqrt()

# train lm with interaction model
lmod_interaction_train <- update(lmod_interaction, data = train)
lmod_interaction_test <- suppressWarnings(predict(lmod_interaction_train, newdata = test))
rmse_lmod_interaction[i] <- (test$attend - lmod_interaction_test)^2 %>% mean() %>% sqrt()
}
cv <- tibble(lmod = rmse_lmod, lmod_interaction = rmse_lmod_interaction) %>%
mutate(dif_rmse = rmse_lmod - rmse_lmod_interaction)
cv %>%
apply(2,mean)
options(warn=-1)

```

Rule for Analysis: If the Diff RMSE value is negative, it means that Variable increases prediction accuracy. If positive , it means that variable decreaes prediction accuracy. If the diff rmse value is really less either positive or negative, it means that including or excluding the variable doesnt effect the model very much.

RMSE value when bobblehead variable is taken out is more as compared to the model where we included Bobblehead. It shows that bobblehead is significant.

# Cross Validation tests : For day_of_week
This tests are done by taking each variable out from the model and then comparing the prediction results with the all variables model


```{r}
set.seed(500)
nfolds <- 5
folds <- rep(seq(5), nrow(d2), len=nrow(d2)) %>% sample()
rmse_lmod <- rep(NA, nfolds)
rmse_lmod_interaction <- rep(NA, nfolds)

lmodnew <-  update(lmod, . ~ .)
lmod_interaction <- update(lmod, . ~ . - day_of_week)

for (i in seq(nfolds)){
train <- d2[folds!=i,]
test <- d2[folds==i,]

# train lm without interaction model
lmod_train <- update(lmodnew, data = train)
lmod_test <- predict(lmod_train, newdata = test)
rmse_lmod[i] <- (test$attend - lmod_test)^2 %>% mean() %>% sqrt()

# train lm with interaction model
lmod_interaction_train <- update(lmod_interaction, data = train)
lmod_interaction_test <- suppressWarnings(predict(lmod_interaction_train, newdata = test))
rmse_lmod_interaction[i] <- (test$attend - lmod_interaction_test)^2 %>% mean() %>% sqrt()
}
cv <- tibble(lmod = rmse_lmod, lmod_interaction = rmse_lmod_interaction) %>%
mutate(dif_rmse = rmse_lmod - rmse_lmod_interaction)
cv %>%
apply(2,mean)
options(warn=-1)

```


RMSE value when day_of_week variable is taken out is more as compared to the model where we included Bobblehead. It shows that day_of_week is significant.

# Cross Validation tests : For fireworks
This tests are done by taking each variable out from the model and then comparing the prediction results with the all variables mode

```{r}
set.seed(461)
options(warn=-1)
nfolds <- 5
folds <- rep(seq(5), nrow(d2), len=nrow(d2)) %>% sample()
rmse_lmod <- rep(NA, nfolds)
rmse_lmod_interaction <- rep(NA, nfolds)

lmodnew <-  update(lmod, . ~ . - month)
lmod_interaction <- update(lmod, . ~ . - month - fireworks)

for (i in seq(nfolds)){
train <- d2[folds!=i,]
test <- d2[folds==i,]

# train lm without interaction model
lmod_train <- update(lmodnew, data = train)
lmod_test <- predict(lmod_train, newdata = test)
rmse_lmod[i] <- (test$attend - lmod_test)^2 %>% mean() %>% sqrt()

# train lm with interaction model
lmod_interaction_train <- update(lmod_interaction, data = train)
lmod_interaction_test <- suppressWarnings(predict(lmod_interaction_train, newdata = test))
rmse_lmod_interaction[i] <- (test$attend - lmod_interaction_test)^2 %>% mean() %>% sqrt()
}
cv <- tibble(lmod = rmse_lmod, lmod_interaction = rmse_lmod_interaction) %>%
mutate(dif_rmse = rmse_lmod - rmse_lmod_interaction)
cv %>%
apply(2,mean)


```


RMSE value when fireowrks variable is taken out is more as compared to the model where we included Bobblehead. It shows that fireworks is significant.
The highest RMSE is when we removed the bobblehead variable. A low RMSE means the model is a better fit. Hence the model fits better when we include bobblehead in prediction.


# c.  Is bobblehead still signiﬁcant? What is expected additional attendance due bobblehead? What is 80% conﬁdence interval? 
```{r}
temp <- subset(d2, bobblehead=="YES")
newdata <- data.frame(temp)
result <- predict(lmod, newdata=newdata, level=0.80, 
        interval = "prediction")
colMeans(result)

```


```{r}
confint(lmod, level = 0.80)["bobbleheadYES",]
```



The additional number of fans only due to bobblehead promotion is 9345. The 80% confidence interval is computed above.

Yes, bobblehead is the most significant predictor of attendance.

# d. Check model diagnostics.
#  i.  Does any quantitative explanatory variable need a nonlinear transformation? 
  
#      Ans.


Now we look at which variables would need nonlinear transformations. We can guess this from looking at the data visualizations of the variables.


```{r}

 d2 %>%
ggplot(aes( temp, attend, group=1)) +
geom_point() +
scale_y_continuous(labels=scales::comma) +
geom_smooth(se=FALSE, method="loess")



```

The temp variable seems like can be modeled by a non linear transformation because of the non linear curve it represents.

#  ii.  Cross Validation on Two interaction terms. 
We will now see how the interaction of two variable terms can modify our model accuray :

# Cross Validation on Temp:Day_night:

```{r}
set.seed(500)
nfolds <- 5
folds <- rep(seq(5), nrow(d2), len=nrow(d2)) %>% sample()
rmse_lmod <- rep(NA, nfolds)
rmse_lmod_interaction <- rep(NA, nfolds)

lmodnew <-  update(lmod, . ~ . )
lmod_interaction <- update(lmod, . ~ . + temp: day_night )

for (i in seq(nfolds)){
train <- d2[folds!=i,]
test <- d2[folds==i,]

# train lm without interaction model
lmod_train <- update(lmodnew, data = train)
lmod_test <- predict(lmod_train, newdata = test)
rmse_lmod[i] <- (test$attend - lmod_test)^2 %>% mean() %>% sqrt()

# train lm with interaction model
lmod_interaction_train <- update(lmod_interaction, data = train)
lmod_interaction_test <- suppressWarnings(predict(lmod_interaction_train, newdata = test))
rmse_lmod_interaction[i] <- (test$attend - lmod_interaction_test)^2 %>% mean() %>% sqrt()
}
cv <- tibble(lmod = rmse_lmod, lmod_interaction = rmse_lmod_interaction) %>%
mutate(dif_rmse = rmse_lmod - rmse_lmod_interaction)
cv %>%
apply(2,mean)
options(warn=-1)
```

Analysis Rule: As we are adding a new variable term hence now if the diff rmse value is more positive it means that the term is significant. 

I chose temperature and day_night as naturally people would like to watch a match in a cosy temperature or in day time or night. As temperature and day night are closely linked, generally higher temperature in days and lower in nights. Here we try to see if we can predict attendance by looking at their relation

Temp and day_night variable interaction reduces the RMSE value and increases diff RMSE. Hence this interaction improves the model.

# Cross Validation on Temp:Day_night:

```{r}
set.seed(500)
nfolds <- 5
folds <- rep(seq(5), nrow(d2), len=nrow(d2)) %>% sample()
rmse_lmod <- rep(NA, nfolds)
rmse_lmod_interaction <- rep(NA, nfolds)

lmodnew <-  update(lmod, . ~ . )
lmod_interaction <- update(lmod, . ~ . + temp:skies)

for (i in seq(nfolds)){
train <- d2[folds!=i,]
test <- d2[folds==i,]

# train lm without interaction model
lmod_train <- update(lmodnew, data = train)
lmod_test <- predict(lmod_train, newdata = test)
rmse_lmod[i] <- (test$attend - lmod_test)^2 %>% mean() %>% sqrt()

# train lm with interaction model
lmod_interaction_train <- update(lmod_interaction, data = train)
lmod_interaction_test <- suppressWarnings(predict(lmod_interaction_train, newdata = test))
rmse_lmod_interaction[i] <- (test$attend - lmod_interaction_test)^2 %>% mean() %>% sqrt()
}
cv <- tibble(lmod = rmse_lmod, lmod_interaction = rmse_lmod_interaction) %>%
mutate(dif_rmse = rmse_lmod - rmse_lmod_interaction)
cv %>%
apply(2,mean)
options(warn=-1)
```

I chose temperature and skies as naturally people would like to watch a match in a cosy temperature plus if there are clouds or not. As temperature and skies are not so much closely linked, generally higher temperature in clear skies and lower in clouded ones. Here we try to see if we can predict attendance by looking at their relation

Temp and day_night variable interaction increases the RMSE value by very small amount. Hence this term is not significant.














